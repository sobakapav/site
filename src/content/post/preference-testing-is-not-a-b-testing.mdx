---
publishDate: 2019-03-05T00:00:00Z
title: Повторяйте за мной. Тестирование предпочтений — это не A/B-тестирование
excerpt: Тестирование предпочтений дает слабые доказательства — данные, собранные таким образом, практически бесполезны. A/B- тестирование, напротив, дает убедительные данные.
author: Перевод статьи Repeat after me. Preference testing is not A/B Testing 
image: ~/assets/images/articles/preference-testing-is-not-a-b-testing/main.jpg
imageAlt: Тестирование предпочтений — это не A/B-тестирование
topic: ИССЛЕДОВАНИЯ
tags:
  - исследования
  - теория
seeMore: |
  ### Вам нужно исследование?
  #### Заказать UX-аудит или исследование пользователей
  Напишите нам на&nbsp;[we@sobakapav.ru](mailto:we@sobakapav.ru)
  #### Что мы можем сделать?
  Что угодно от [аудита интерфейса](/services/ux-audit) до [продуктового исследования](/services/research). 
  #### Примеры из практики
  Мы наверняка уже делали проект, пожожий на то, что вам нужно. [Проверьте](https://sobakapav.ru/portfolio).
relatedLinks:
  title: Примеры работ
  links:
    - qiwi
    - medmarket
    - sportmaster
metadata:
  canonical: https://sobakapav.ru/publications/preference-testing-is-not-a-b-testing
  title: Повторяйте за мной. Тестирование предпочтений — это не A/B-тестирование • UX-исследования
  description: "Тестирование предпочтений дает слабые доказательства — данные, собранные таким образом, практически бесполезны. A/B- тестирование, напротив, дает убедительные данные."
  robots:
    index: true
    follow: true
  openGraph:
    site_name: Собака Павлова
    type: website
---

import DListItem from '~/components/ui/DListItem.astro';
import ToggleTheme from '~/components/common/ToggleTheme.astro';

Иногда исследователи спрашивают участников тестирования, какой из двух вариантов дизайна им нравится больше. Данные, полученные в ходе таких исследований, — это мнения, прогностическая ценность которых невелика. Многофакторное A/B-тестирование, напротив, предполагает, что целевая аудитория выполняет реальные задачи. Данные таких исследований содержат наблюдения за поведением, которые позволяют предсказывать образ действий в реальной жизни.

Проектировщики быстро приходят к выводу, что не стоит ограничиваться всего одной версией дизайна. Они создают несколько вариантов — скажем, три-пять, что позволяет изучить альтернативы. Но как решить, какой версии отдать предпочтение? Либо последнее слово остается за клиентом, либо приходится обращаться к пользователям, ставя вопрос на голосование.

Исследователи — а уж они-то, казалось бы, должны разбираться в вопросе — иногда называют такой метод A/B-тестированием. Они берут две версии дизайна — A и B — и пытаются выяснить, какую из них предпочитают участники.

Но это не A/B-тестирование. Это тестирование предпочтений. И различия тут не семантические. В книге [Think Like a UX Researcher](http://uxresearchbook.com/) («Рассуждай как UX-исследователь»), которую я написал вместе с Филипом Ходжсоном, мы разбили данных UX-исследований на три группы — по силе доказательств.

- **Убедительные доказательства:** данные о том, как целевые пользователи выполняют задачи или совершают действия, имеющие отношение к разрабатываемому продукту.
- **Умеренно убедительные доказательства:** данные исследований, которые предполагают как минимум выполнение задач. Их выполняют пользователи или эксперты по юзабилити, которые сами описывают свои действия.
- **Слабые доказательства:** данные, полученные методами, которые либо ошибочны, либо немногим лучше гадания на кофейной гуще.

Тестирование предпочтений дает слабые доказательства — данные, собранные таким образом, практически бесполезны. A/B- тестирование, напротив, дает убедительные данные.

### Что такое A/B-тестирование?

A/B-тестирование — в отличие от тестирования предпочтений — это разновидность многофакторного тестирования. A/B-тестирование проводится на реальном сайте. Половина посетителей видит одну версию страницы (дизайн A), другая половина — ее же в слегка измененном виде (дизайн B). Команда разработчиков использует A/B-тесты, чтобы проверить, как работают призывы к действию, цены на продукцию и изображения на посадочных страницах. «Побеждает» тот дизайн, который лучше прочих стимулирует желаемое поведение (например, покупки, пожертвования или подписку на новостную рассылку).

Один из моих любимых примеров A/B-тестирования связан с Google. Когда Google запустил рекламу в Gmail, команда разработчиков решила оптимизировать цвет гиперссылок. Они протестировали сорок оттенков синего и обнаружили, что [легкий фиолетовый оттенок повышает число кликов по сравнению с зеленоватым](https://www.theguardian.com/technology/2014/feb/05/why-google-engineers-designers). По результатам тестирования компания выбрала фиолетово-синий цвет, что увеличило ее доходы на 200 миллионов долларов в год.

### В чем минусы тестирования предпочтений?

Представьте, что мы будем спрашивать участников тестирования, какой из сорока оттенков синего нравится им больше всего. Неужели люди выберут фиолетовый, который повышает число кликов? Разумеется, нет. Такая формулировка звучит нелепо. Но тогда почему все продолжают упорно заниматься тестированием предпочтений?

Дело в том, что подобные методы на первый взгляд обладают внешней валидностью. Опросы такого рода популярны при изучении рынка, когда маркетологам нужно выяснить, какие визуальные образы, логотип или символика бренда нравятся людям.

Но UX-исследования — это не анализ рынка. Есть по меньшей мере четыре причины, по которым тестирование предпочтений играет второстепенную роль в UX-исследованиях — или не играет вообще никакой роли.

### Тестирование предпочтений не отражает использование в реальной жизни

Задавая вопрос о предпочтениях, исследователи обычно демонстрируют участникам два варианта и просят выбрать тот, что нравится больше. Например: «Какой вариант дизайна вам больше нравится: A или B?» или «Какое расположение панели навигации вы считаете предпочтительным: в правой или в левой части экрана?"

Но это не имеет ничего общего с тем, как люди выносят суждения в реальности. В реальном мире они не выбирают из двух веб-страниц ту, что нравится больше. Они просто используют продукт, чтобы достичь цели. Если их просят отдать предпочтение дизайну, которым они не пользовались, им приходится задумываться о менее важных моментах. Например, о внешнем виде продукта, о том, кажется ли он знакомым и соответствует ли их вкусу (предположим, кто-то не выносит оранжевый цвет). Между тем UX-исследователь должен сфокусировать внимание на использовании и лояльности в долгосрочной перспективе («могу ли я с помощью этого продукта делать то, что мне нужно?»).

### Люди не заинтересованы в результате

Да, люди знают, что они предпочитают. Вы наверняка сразу скажете, что или кто вам нравится больше: кока-кола или пепси, Apple или Microsoft, ваша подруга Эми или ваша подруга Дженис. Но вы не отдаете себе отчет, почему испытываете подобные чувства. Тестирование предпочтений заставляет людей анализировать причины своего выбора, чтобы команда разработчиков могла определить, в каком направлении двигаться. Часто участникам задают вопросы вроде «Почему дизайн A нравится вам больше, чем B?» или «Почему вы предпочитаете, чтобы панель навигации была слева?». Но [оказывается, люди не умеют отвечать на такие вопросы](https://www.userfocus.co.uk/articles/askingwhy.html). Они не знают почему, отвечают, не задумываясь, или просто не желают это обсуждать. Большинство людей, когда кто-то интересуется их мнением, сочиняют на ходу. Они не взвешивают свои слова и не ищут глубинные причины. Это не значит, что UX-исследователям наплевать, что нравится людям, — просто принимать серьезные проектные решения, опираясь на переменчивые мнения, рискованно.

### Тестирование предпочтений заставляет людей предсказывать будущее

Тестирование предпочтений требует, чтобы люди представили будущее, в котором существуют две версии дизайна, и предугадали, какую из них они будут использовать. Исследования показывают, что люди обычно не сильны в прогнозировании своего поведения. Они ошибаются на каждом шагу — пытаясь предсказать время, которое потребуется для выполнения работы, вероятность долгих и счастливых отношений, сколько денег они сумеют отложить, как сдадут экзамены, сколько будут жертвовать на благотворительность и смогут ли вести здоровый образ жизни. Лучший прогностический фактор поведения пользователей в будущем — это их поведение в прошлом, а не мнение в настоящий момент. Вместо того чтобы спрашивать людей, что они предпочитают, нам нужно выяснить, какой вариант позволяет им лучше всего выполнять свои задачи.

### Тестирование предпочтений смешивает вопрос исследования с вопросами для интервью

Вопрос исследования — это его цель. Он определяет методику проведения исследования. Пример такого вопроса: лучше ли дизайн A, чем дизайн B.

Однако вопрос исследования — это не те вопросы, которые вы задаете участникам. Допустим, цель вашего исследования — выяснить: «Влияет ли езда на велосипеде на производительность труда работников?» Но вы не можете задавать этот вопрос участникам, рассчитывая услышать содержательные ответы. Вместо этого можно спросить: «Сколько раз в неделю вы ездите на работу на велосипеде?» или «Что мешает вам ездить на велосипеде чаще?» — а потом сравнить полученные данные с показателями производительности.

На самом деле, чтобы ответить на вопрос исследования, далеко не всегда нужно задавать вопросы участникам. Вы можете просто попросить их выполнять определенные задачи и наблюдать, как они это делают (юзабилити-тестирование). Эту мысль хорошо выразил Роб Фитцпатрик в книге «[Спроси маму](https://www.ozon.ru/context/detail/id/140446253/?utm_source=yandex_direct&utm_medium=cpc&utm_campaign=product_1132527_mspt_dsa_all_books_business_33218413&utm_term=_cbrx_642888)»:

«Попытки получить нужную информацию, беседуя с клиентами, можно сравнить с археологическими раскопками. И здесь и там нужна деликатность. Правда где-то рядом, но какая же она хрупкая. Каждый взмах лопаты приближает вас к ней, но, выбрав слишком грубый инструмент, вы рискуете раздробить добытое сокровище на миллион обломков».

### Юзабилити-тестирование: круче только машина времени

Недостаток A/B-тестирования в том, что вы не можете использовать его на ранней стадии проектирования. Что если у нас есть два прототипа концепции и мы хотим сравнить их? Вероятно, поэтому тестирование предпочтений кажется людям таким притягательным.

Вот почему и было изобретено юзабилити-тестирование. Теперь, вместо того чтобы выяснять у людей, что они предпочитают, мы просим их воспользоваться прототипом и выявляем проблемы, которые нужно решить.

К ним относятся любые негативные моменты, которые:
- препятствуют выполнению задачи;
- тормозят действия участника;
- вынуждают отклониться от курса;
- создают впечатление, что задача выполнена (когда это не так);
- заставляют искать обходные пути;
- ставят участника в тупик;
- раздражают или сердят участника;
- заставляют делать ошибки;
- мешают заметить нечто важное;
- дают понять, что все в порядке (когда это не так);
- заставляют неправильно истолковывать контент;
- мешают сделать следующий шаг.

Юзабилити-тестирование позволяет получить убедительные результаты, поскольку опирается на поведение: мы исследуем то, что люди делают, а не то, что они говорят. Этот метод немногим хуже машины времени: мы проецируем участника тестирования в будущее, когда ваша идея станет реальным продуктом, и можем увидеть, как этот продукт выполняет свои задачи.

### * * *

При планировании исследований пользовательской аудитории следует знать базовые принципы психологии. [Здесь вы найдете четыре фундаментальных принципа](https://www.userfocus.co.uk/articles/field-guide-to-psychology.html).

### Об авторе

[Дэвид Трэвис](https://www.userfocus.co.uk/about/profiles.html#Anchor-David-47857) ([@userfocus](https://medium.com/@userfocus)) занимается этнографическими исследованиями и юзабилити-тестированием с 1989 года. Он опубликовал три книги о пользовательском опыте, в том числе [Think Like a UX Researcher](http://uxresearchbook.com/) («Мысли как UX-исследователь»). Если вам нравятся его статьи, вы можете пройти его [онлайн-курс по пользовательскому опыту со скидкой](http://uxtraining.net/).

[Оригинал статьи](https://www.userfocus.co.uk/articles/preference-testing-is-not-A-B-testing.html)

